{"spans": [{"name": "RunnableSequence", "context": {"span_id": "0x2b537993fd22abe3", "trace_id": "0xc7acd1bda0d0e4c171e7dd3d702bc551"}, "parent_id": null, "start_time": 1736519648621722300, "end_time": 1736519653942216800, "status_code": "ERROR", "status_message": "Service Unavailable", "attributes": {"mlflow.traceRequestId": "\"4e510d91e5b74554862b74a78165b1a9\"", "mlflow.spanType": "\"CHAIN\"", "mlflow.spanInputs": "{\"instructions\": \"\", \"human_input\": \"Hi\"}"}, "events": [{"name": "exception", "timestamp": 1736519653942216, "attributes": {"exception.message": "Service Unavailable", "exception.type": "APIError", "exception.stacktrace": "APIError('Service Unavailable')Traceback (most recent call last):\n\n\n  File \"c:\\users\\divyam190916\\downloads\\gptprompthelp-main\\gptprompthelp-main\\venv2\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n    input = context.run(step.invoke, input, config)\n\n\n  File \"c:\\users\\divyam190916\\downloads\\gptprompthelp-main\\gptprompthelp-main\\venv2\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 460, in safe_patch_function\n    return original(*args, **kwargs)\n\n\n  File \"c:\\users\\divyam190916\\downloads\\gptprompthelp-main\\gptprompthelp-main\\venv2\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n    self.generate_prompt(\n\n\n  File \"c:\\users\\divyam190916\\downloads\\gptprompthelp-main\\gptprompthelp-main\\venv2\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n\n\n  File \"c:\\users\\divyam190916\\downloads\\gptprompthelp-main\\gptprompthelp-main\\venv2\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n    raise e\n\n\n  File \"c:\\users\\divyam190916\\downloads\\gptprompthelp-main\\gptprompthelp-main\\venv2\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n    self._generate_with_cache(\n\n\n  File \"c:\\users\\divyam190916\\downloads\\gptprompthelp-main\\gptprompthelp-main\\venv2\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n    result = self._generate(\n\n\n  File \"c:\\users\\divyam190916\\downloads\\gptprompthelp-main\\gptprompthelp-main\\venv2\\lib\\site-packages\\langchain_groq\\chat_models.py\", line 467, in _generate\n    return generate_from_stream(stream_iter)\n\n\n  File \"c:\\users\\divyam190916\\downloads\\gptprompthelp-main\\gptprompthelp-main\\venv2\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 88, in generate_from_stream\n    generation = next(stream, None)\n\n\n  File \"c:\\users\\divyam190916\\downloads\\gptprompthelp-main\\gptprompthelp-main\\venv2\\lib\\site-packages\\langchain_groq\\chat_models.py\", line 509, in _stream\n    for chunk in self.client.create(messages=message_dicts, **params):\n\n\n  File \"c:\\users\\divyam190916\\downloads\\gptprompthelp-main\\gptprompthelp-main\\venv2\\lib\\site-packages\\groq\\_streaming.py\", line 46, in __iter__\n    for item in self._iterator:\n\n\n  File \"c:\\users\\divyam190916\\downloads\\gptprompthelp-main\\gptprompthelp-main\\venv2\\lib\\site-packages\\groq\\_streaming.py\", line 91, in __stream__\n    raise APIError(\n\n\ngroq.APIError: Service Unavailable"}}]}, {"name": "ChatPromptTemplate", "context": {"span_id": "0x105c2e20cf6d3dae", "trace_id": "0xc7acd1bda0d0e4c171e7dd3d702bc551"}, "parent_id": "0x2b537993fd22abe3", "start_time": 1736519648621722300, "end_time": 1736519648622719300, "status_code": "OK", "status_message": "", "attributes": {"mlflow.traceRequestId": "\"4e510d91e5b74554862b74a78165b1a9\"", "mlflow.spanType": "\"CHAIN\"", "mlflow.spanInputs": "{\"instructions\": \"\", \"human_input\": \"Hi\"}", "mlflow.spanOutputs": "{\"messages\": [{\"content\": \"\", \"additional_kwargs\": {}, \"response_metadata\": {}, \"type\": \"system\", \"name\": null, \"id\": null}, {\"content\": \"Hi\", \"additional_kwargs\": {}, \"response_metadata\": {}, \"type\": \"human\", \"name\": null, \"id\": null, \"example\": false}]}"}, "events": []}, {"name": "ChatGroq", "context": {"span_id": "0xd59a0d2b3341d162", "trace_id": "0xc7acd1bda0d0e4c171e7dd3d702bc551"}, "parent_id": "0x2b537993fd22abe3", "start_time": 1736519648623716400, "end_time": 1736519653937721400, "status_code": "ERROR", "status_message": "Service Unavailable", "attributes": {"mlflow.traceRequestId": "\"4e510d91e5b74554862b74a78165b1a9\"", "mlflow.spanType": "\"CHAT_MODEL\"", "invocation_params": "{\"_type\": \"groq-chat\", \"stop\": null}", "options": "{\"stop\": null}", "batch_size": "1", "metadata": "{\"ls_provider\": \"groq\", \"ls_model_name\": \"llama-3.3-70b-versatile\", \"ls_model_type\": \"chat\", \"ls_temperature\": 1e-08}", "mlflow.spanInputs": "[[{\"content\": \"\", \"additional_kwargs\": {}, \"response_metadata\": {}, \"type\": \"system\", \"name\": null, \"id\": null}, {\"content\": \"Hi\", \"additional_kwargs\": {}, \"response_metadata\": {}, \"type\": \"human\", \"name\": null, \"id\": null, \"example\": false}]]"}, "events": [{"name": "exception", "timestamp": 1736519653937721, "attributes": {"exception.message": "Service Unavailable", "exception.type": "APIError", "exception.stacktrace": "APIError('Service Unavailable')Traceback (most recent call last):\n\n\n  File \"c:\\users\\divyam190916\\downloads\\gptprompthelp-main\\gptprompthelp-main\\venv2\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n    self._generate_with_cache(\n\n\n  File \"c:\\users\\divyam190916\\downloads\\gptprompthelp-main\\gptprompthelp-main\\venv2\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n    result = self._generate(\n\n\n  File \"c:\\users\\divyam190916\\downloads\\gptprompthelp-main\\gptprompthelp-main\\venv2\\lib\\site-packages\\langchain_groq\\chat_models.py\", line 467, in _generate\n    return generate_from_stream(stream_iter)\n\n\n  File \"c:\\users\\divyam190916\\downloads\\gptprompthelp-main\\gptprompthelp-main\\venv2\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 88, in generate_from_stream\n    generation = next(stream, None)\n\n\n  File \"c:\\users\\divyam190916\\downloads\\gptprompthelp-main\\gptprompthelp-main\\venv2\\lib\\site-packages\\langchain_groq\\chat_models.py\", line 509, in _stream\n    for chunk in self.client.create(messages=message_dicts, **params):\n\n\n  File \"c:\\users\\divyam190916\\downloads\\gptprompthelp-main\\gptprompthelp-main\\venv2\\lib\\site-packages\\groq\\_streaming.py\", line 46, in __iter__\n    for item in self._iterator:\n\n\n  File \"c:\\users\\divyam190916\\downloads\\gptprompthelp-main\\gptprompthelp-main\\venv2\\lib\\site-packages\\groq\\_streaming.py\", line 91, in __stream__\n    raise APIError(\n\n\ngroq.APIError: Service Unavailable"}}]}], "request": "{\"instructions\": \"\", \"human_input\": \"Hi\"}", "response": null}